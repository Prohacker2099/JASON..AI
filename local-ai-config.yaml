server:
  port: 8080
  host: localhost
  max_tokens: 8192
  temperature: 0.7
  streaming: true
  websocket_enabled: true

models:
  - name: jason-core
    backend: llama
    parameters:
      model: ggml-gpt4all-j.bin
      context_size: 4096
      threads: 8
      batch_size: 1024
      top_p: 0.9
      top_k: 40
      repeat_penalty: 1.1
    capabilities:
      - text_generation
      - code_generation
      - task_planning
      - sentiment_analysis

  - name: jason-vision
    backend: stable-diffusion
    parameters:
      model: runwayml/stable-diffusion-v1-5
      compute_type: float16
      batch_size: 4
      scheduler: DPMSolverMultistep
    capabilities:
      - image_generation
      - style_transfer
      - image_editing

embeddings_models:
  - name: jason-embeddings
    backend: transformers
    parameters:
      model: sentence-transformers/all-MiniLM-L6-v2
      pooling: mean
      max_seq_length: 512
    capabilities:
      - semantic_search
      - clustering
      - similarity_analysis

audio_models:
  - name: jason-voice
    backend: whisper
    parameters:
      model: large-v2
      compute_type: float16
      language: auto
      task: transcribe
    capabilities:
      - speech_recognition
      - voice_activity_detection
      - language_identification

nlp_models:
  - name: jason-nlp
    backend: transformers
    parameters:
      model: microsoft/deberta-v3-large
    capabilities:
      - intent_classification
      - named_entity_recognition
      - sentiment_analysis
      - emotion_detection

real_time_processing:
  enabled: true
  max_concurrent_requests: 10
  priority_queue: true
  latency_optimization: true

security:
  encryption_enabled: true
  api_key_required: true
  rate_limiting:
    enabled: true
    requests_per_minute: 60
  cors:
    enabled: true
    allowed_origins: ["http://localhost:3000"]

monitoring:
  enabled: true
  metrics:
    - latency
    - throughput
    - error_rate
    - model_performance
  logging:
    level: info
    format: json

caching:
  enabled: true
  type: redis
  ttl: 3600
  max_size: "2GB"
